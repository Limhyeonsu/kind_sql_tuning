# DML 튜닝
## 6.1 기본 DML 튜닝
### 6.1.1 DML 성능에 영향을 미치는 요소
* 인덱스
* 무결성 제약
* 조건절
* 서브쿼리
* Redo 로깅
* Undo 로깅
* Lock
* 커밋

__인덱스와 DML 성능__ : 테이블에 레코드 입력시 인덱스에도 입력해야한다. 테이블은 입력할 블록을 할당받지만 인덱스는 정렬된 자료구조라 입력할 블록을 찾아야한다. DELETE, UPDATE의 경우에도 마찬가지다. 인덱스의 개수가 DML 성능에 미치는 영향이 매우 크므로 인덱스 설계를 신경써야한다.

__무결성 제약과 DML 성능__ : 데이터 무결성 규칙 1)개체 무결성 2)참조 무결성 3)도메인 무결성 4)사용자 정의 무결성 PK, FK 제약은 CHECK, NOT NULL 제약보다 성능에 더 큰 영향을 미친다. 

__조건절과 DML 성능__

__서브쿼리와 DML 성능__

__Redo로깅과 DML 성능__ : 오라클은 데이터 파일과 컨트롤 파일에 가해지는 모든 변경사항을 Redo 로그에 기록한다. Redo 로그는 트랜잭션 데이터가 어떤 이유에서건 유실되었을 때 트랜잭션을 재현함으로써 유실 이전 상태로 복구하는 데 사용된다.

Redo로그는 다음의 세 가지 목적에 사용된다.

1) Database Recovery : 물리적으로 디스크가 깨지는 등의 Media Fail 발생 시 데이터베이스를 복구하기 위해 사용한다.
2) Cache Recovery : 버퍼캐시는 휘발성이다. 캐시에 저장된 변경사항이 디스크 상의 데이터 블록에 아직 기록되지 않은 상태에서 정전 등이 발생하여 인스턴스가 비정상적으로 종료되면 작업내용을 잃게 된다. 이러한 트랜잭션 데이터 유실에 대비하기 위해 로그를 남긴다.
3) Fast Commit : 트랜잭션에 의한 변경사항을 우선 Append 방식으로 빠르게 로그 파일에 기록하고, 변경된 메모리 버퍼블록과 데이터파일 블록 간 동기화는 적절한 수단을 이용해 나중에 배치 방식으로 일괄 수행한다. 사용자의 갱신 내용이 메모리상의 버퍼블록에만 기록된 채 아직 디스크에 기록되지 않았지만 Redo 로그를 믿고 빠르게 커밋을 완료한다는 의미에서 Fast Commit이라고 부른다.

__Undo 로깅과 DML 성능__ : Redo는 트랜잭션을 재현함으로써 과거를 현재 상태로 되돌리는 데 사용하고, Undo는 트랜잭션을 롤백함으로써 현재를 과거 상태로 되돌리는 데 사용한다. DML을 수행할 때마다 Undo에 변경된 블록을 이전 상태로 되돌리는 데 필요한 정보를 로깅하므로 DML 성능에 영향을 미친다.

Undo로그는 다음의 세 가지 목적에 사용된다.

1) Transaction Rollback : 트랜잭션에 의한 변경사항을 최종 커밋하지 않고 롤백하고자 할 때 이용
2) Transaction Recover : Instance Crash 발생 후 Redo를 이용해 roll forward 단계가 완료되면 최종 커밋되지 않은 변경사항까지 모두 복구 된다.
3) Read Consistency : 읽기 일관성을 위해 사용한다.

__MVCC(Multi-Version Concurrency Control)모델__ : MVCC 모델을 사용하는 오라클은 데이터를 두 가지 모드로 읽는다.

1) Current 모드 : 디스크에서 캐시로 적재된 원본 블록을 현재 상태 그대로 읽는 방식
2) Consistent 모드 : 쿼리가 시작된 이후에 다른 트랜잭션에 의해 변경된 블록을 만나면 원본 블록으로부터 복사본 블록을 만들고, 거기에 Undo 데이터를 적용함으로써 쿼리가 시작된 시점으로 되돌려서 읽는 방식

오라클은 시스템에서 마지막 커밋이 발생한 시점정보를 'SCN'이라는 Global변수 값으로 관리한다. 각 블록이 마지막으로 변경된 시점을 관리하기 위해 모든 블록 헤더에 SCN을 기록하는데 이를 '블록 SCN'이라고 하고, 모든 쿼리는 Global 변수인 SCN 값을 먼저 확인하고서 읽기 작업을 시작하는데 이를 '쿼리 SCN'이라고 한다. Consistent 모드는 쿼리 SCN과 블록 SCN을 비교함으로써 쿼리 수행 도중에 블록이 변경됐는지 확인하면서 데이터를 읽는 방식이다.

__Lock과 DML 성능__ : Lock은 DML 성능에 매우 크고 직접적인 영향을 미친다. Lock을 필요 이상으로 자주 길게 사용하거나 레빌을 높일수록 DML 성능은 느려진다. 그렇다고 너무 적게 짧게 사용하거나 필요한 레벨 이하로 낮추면 데이터 품질이 나빠진다.

__커밋과 DML 성능__ : DML이 Lock에 의해 블로킹된 경우 커밋은 DML 성능과 직결된다. 

[커밋의 내부 메커니즘]
1) DB버퍼캐시 : 버퍼캐시에서 변경된 블록을 모아 주기적으로 데이터 파일에 일괄기록하는 직업은 DBWR 프로세스가 맡는다. 
2) Redo 로그버퍼 : 버퍼캐시는 휘발성인데 버퍼캐시에 가한 변경사항을 Redo 로그에도 기록하여 버퍼캐시 데이터가 유실되더라도 Redo로그를 이용해 언제든 복구할 수 있다. Redo 로깅 성능 문제를 해결하기 위해 오라클은 로그버퍼를 이용한다. (Redo 로그 파일에 기록하기 전에 먼저 로그버퍼에 기록하는 방식)
3) 트랜잭션 데이터 저장 과정
4) 커밋 = 저장 버튼 : 커밋은 문서작업에 비유하면 저장 버튼을 누르는것과 같다. 서버 프로세스가 그때까지 했던 작업을 디스크에 기록하라는 명령어인 셈이다. 트랜잭션을 필요 이상으로 길게 정의함으로써 오랫동안 커밋하지 않는 것도 문제고, 너무 자주 커밋하는 것도 문제다. 따라서 트랜잭션을 논리적으로 잘 정의함으로써 불필요한 커밋이 발생하지 않도록 구현해야한다.

### 6.1.2 데이터베이스 Call과 성능
SQL은 세 단계로 나누어 실행된다.

* Parse Call : SQL 파싱과 최적화를 수행하는 단계
* Execute Call : SQL을 실행하는 단계, DML은 이 단계에서 모든 과정이 끝난다.
* Fetch Call : 데이터를 읽어서 사용자에게 결과 집합을 전송하는 과정 (SELECT)

Call이 어디서 발생하느냐에 따라 User Call과 Recursive Call로 나눌 수 있다. User Call은 WAS서버에서 발생하는 Call이고, Recursive Call은 DBMS 내부에서 발생하는 Call이다.(SQL 파싱과 최적화 과정에서 발생하는 데이터 딕셔너리 조회, PL/SQL로 작성한 사용자 정의 함수/프로시저/트리거에 내장된 SQL을 실행할 때 발생하는 Call이 해당)

### 6.1.3 Array Processing 활용
Array Processing 기능을 활용하면 One SQL로 구현하지 않고도 Call 부하를 획기적으로 줄일 수 있다.

### 6.1.4 인덱스 및 제약 해제를 통한 대량 DML 튜닝
인덱스와 무결성 제약 조건은 DML 성능에 큰 영향을 끼친다. 그렇다고 온라인 트랜잭션 처리 시스템에서 이들 기능을 해제할 순 없다. 반면 동시 트랜잭션 없이 대량 데이터를 적재하는 배치 프로그램에서는 이들 기능을 해체함으로써 큰 성능개선 효과를 얻을 수 있다.

419~421p

### 6.1.5 수정가능 조인뷰
422~424p

조인 뷰는 FROM 절에 두 개 이상 테이블을 가진 뷰를 가리키며, 수정가능 조인뷰는 입력, 수정, 삭제가 허용되는 조인 뷰를 말한다. 단, 1쪽 집합과 조인하는 M쪽 집합에만 입력, 수정, 삭제가 허용된다. 옵티마이저가 지금 어느 테이블이 1쪽 집합인지 알 수 없기 때문에 1쪽 집합에 PK 제약을 설정하거나, Unique 인덱스를 생성해야 수정가능 조인뷰를 통한 입력, 수정, 삭제가 가능하다. PK 제약을 설정한 테이블은 '키-보존 테이블'이 되고(조인된 결과집합을 통해서 중복값 없이 Unique하게 식별이 가능한 테이블), 아닌쪽은 '비 키-보존 테이블'로 남는다.

### 6.1.6 MERGE문 활용

    -- Source 테이블(customer_delta) 기준으로 Target 테이블(customer)과 Left outer join 방식으로 조인에 성공하면 update, 실패하면 insert 한다. 
    merge into customer t using customer_delta s on (t.cust_id = s.cust_id)
    when matched then update
     set t.cust_nm = s.cust_nm, t.email = s.email, ...
     where reg_dt >= to_date('20000101', 'yyyymmdd')  --조건절 추가 가능
    when not matched then insert
     (.....) values (.....)
     where ....


    -- 이미 저장된 데이터를 조건에 따라 삭제기능도 제공함.
    merge into customer t using customer_delta s on (t.cust_id = s.cust_id)
    when matched then
     update set t.cust_nm = s.cust_nm, t.email = s.email, ...
     delete where t.withdraw_dt is not null   --탈퇴일시가 null이 아닌 레코드 삭제
    when not matched then insert
     (.....) values (.....)

delete의 경우 merge문에서 update가 이루어진 결과로서 탈퇴일시가 null이 아닌 레코드만 삭제한다. 즉 탈퇴일시가 null이 아니었어도 merge문을 수행한 결과가 null이면 삭제하지 않는다. 또 merge문 delete절은 조인에 성공한 데이터만 삭제할 수 있다. (조인에 성공한 데이터를 모두 update하고서 그 결과 값이 delete where 조건절을 만족하면 삭제)

## 6.2 Direct Path I/O 활용
### 6.2.1 Direct Path I/O
일반적인 블록 I/O는 DB버퍼캐시를 경유한다. 대량 데이터를 읽고 쓸 때는 건건이 버퍼캐시를 탐색할시 프로그램의 성능이 안 좋아진다. 따라서 다음의 경우 오라클은 버퍼캐시를 경유하지 않고 곧바로 데이터 블록을 읽고 쓸 수 있는 Direct Path I/O기능을 제공한다.

* 병렬 쿼리로 Full Scan을 수행할 때
* 병렬 DML을 수행할 때
* Direct Path Insert를 수행할 때
* Temp 세그먼트 블록들을 읽고 쓸 때
* direct 옵션을 지정하고 export를 수행할 때
* nocache 옵션을 지정한 LOB컬럼을 읽을 때

### 6.2.2 Direct Path Insert
일반적인 Insert가 느린이유는 

1) 데이터를 입력할 수 있는 블록을 Freelist에서 찾는다.
2) Freelist에서 할당받은 블록을 버퍼캐시에서 찾는다.
3) 버퍼캐시에 없으면, 데이터파일에서 읽어 버퍼캐시에 적재한다.
4) Insert 내용을 Undo 세그먼트에 기록한다.
5) Insert 내용을 Redo 로그에 기록한다.

Direct Path Insert 방식을 사용하면 대량 데이터를 일반적인 Insert보다 훨씬 더 빠르게 입력할 수 있다. 사용 방법은 1)Insert ... Select 문에 append 힌트 사용 2)parallel 힌트를 이용해 병렬 모드로 Insert 3)direct 옵션을 지정하고 SQL*Loader로 데이터 적재 4)CTAS문 수행

Direct Path Insert이 빠른 이유는

1) Freelist를 참조하지 않고 데이터를 순차적으로 입력
2) 블록을 버퍼캐시에서 탐색하지 않는다.
3) 버퍼캐시에 적재하지 않고, 데이터파일에 직접 기록
4) Undo 로깅을 안 한다.
5) Redo 로깅을 안 하게 할 수 있다.(nologging 모드로 전환 : alter table t NOLOGGING)

Direct Path Insert를 사용시 주의할 점

1) 성능은 비교할 수 없이 빨라지지만 Exclusive 모드 TM Lock이 걸린다. 따라서 커밋하기 전까지 다른 트랜잭션은 해당 테이블에 DML을 수행하지 못한다. *트랜잭션이 빈번한 주간에 이 옵션을 사용하는 것은 금물
2) Freelist를 조회하지 않기 때문에 테이블에 여유 공간이 있어도 재활용하지 않는다.

### 6.2.3 병렬 DML
Insert는 append 힌트를 이용해 Direct Path Write 방식으로 유도할 수 있지만 Update, Delete는 기본적으로 Direct Path Write가 불가능하다. 유일한 방법은 병렬 DML로 처리하는 것이다. 

DML을 병렬로 처리하려면 'alter session enable parallel dml;' 로 병렬 DML을 활성화해야한다. 그리고 각 DML 문에 힌트를 사용하여 대상 레코드를 찾는 작업과 데이터 추가/변경/삭제도 병렬로 진행한다.

    insert /*+ parallel(c 4) */ into 고객 c
    select /*+ full(o) parallel(o 4) */ * from 외부가입고객 o;

    update /*+ full(c) parallel(c 4) */ 고객 c set 고객상태코드 = 'WD'
    where 최종거래일시 < '20100101';

    delete /*+ full(c) parallel(c 4) */ from 고객 c 
    where 탈퇴일시 < '20100101';

만약 힌트를 기술했는데 병렬 DML을 활성화하지 않으면 대상 레코드를 찾는 작업은 병렬로 하지만 추가, 변경, 삭제는 QC(Query Coordinator)가 혼자 담당하므로 병목이 생긴다. (12버전부터는 enable_parallel_dml 힌트도 지원)

__병렬 DML이 잘 작동하는지 확인하는 방법__ : 실행계획을 봤을 때 UPDATE, DELETE, INSERT가 'PX COORDINATOR' 아래쪽에 나타나면 각 병렬 프로세스가 처리한다. 반면 'PX COORDINATOR' 위쪽에 나타나면 QC가 처리한다.

    -- 병렬 프로세스가 처리
    | 0| UPDATE STATEMENT      |
    | 1|  PX COORDINATOR       |
    | 2|   PX SEND QC (RANDOM) |
    | 3|    UPDATE             |
    .....

    -- QC가 처리
    | 0| UPDATE STATEMENT      |
    | 1|  UPDATE               |
    | 2|   PX COORDINATOR      |
    | 3|   PX SEND QC (RANDOM) |
    .....

## 6.3 파티션을 활용한 DML 튜닝
### 6.3.1 테이블 파티션
파티셔닝은 테이블 또는 인덱스 데이터를 특정 컬럼 값에 따라 별도 세그먼트에 나눠서 저장하는 것을 말한다.

[파티션이 필요한 이유]
* 관리적 측면 : 파티션 단위 백업, 추가, 삭제, 변경 -> 가용성 향상
* 성능적 측면 : 파티션 단위 조회 및 DML, 경합 또는 부하 분산

1) Range 파티션 : 가장 기초적인 방식으로 주로 날짜 컬럼을 기준으로 파티셔닝한다. 이력성 데이터를 Full Scan 방식으로 조회할 때 성능을 크게 향상한다. 파티션 테이블에 대한 SQL 성능 향상 원리는 파티션 Pruning에 있다. 파티션 Pruning은 SQL하드파싱이나 실행 시점에 조건절을 분석해서 읽지 않아도 되는 파티션 세그먼트를 액세스 대상에서 제외하는 기능이다.
2) Hash 파티션 : 파티션 키 값을 해시 함수에 입력해서 반환받은 값이 같은 데이터를 같은 세그먼트에 저장하는 방식이다. 고객ID처럼 변별력이 좋고 데이터 분포가 고른 컬럼을 파티션 기준으로 선정해야 효과적이다.
3) List 파티션 : 사용자가 정의한 그룹핑 기준에 따라 데이터를 분할 저장하는 방식이다. Range 파티션과 다르게 순서와 상관없이 불연속적인 값의 목록에 의해 결정된다.

### 6.3.2 인덱스 파티션
인덱스는 각 파티션이 커버하는 테이블 파티션 범위에 따라 로컬과 글로벌로 나뉜다. 로컬 파티션 인덱스는 각 테이블 파티션과 인덱스 파티션이 서로 1:1 대응 관계가 되도록 오라클이 자동으로 관리하는 파티션 인덱스를 말한다. 로컬이 아닌 파티션 인덱스는 모두 글로벌 파티션 인덱스이며, 테이블 파티션과 독립적인 구성을 갖는다. 

파티션 인덱스를 Prefixed(인덱스 파티션 키 컬럼이 인덱스 키 컬럼 왼쪽 선두에 위치), NonPrefixed(인덱스 파티션 키 컬럼이 인덱스 키 컬럼 왼쪽 선두에 위치하지 않음)로 나눌 수도 있다. 

인덱스 파티션과 관련해 반드시 기억해야 할 중요한 제약으로 "Unique 인덱스를 파티셔닝하려면 파티션 키가 모두 인덱스 구성 컬럼이어야 한다."

### 6.3.3 파티션을 활용한 대량 UPDATE 튜닝
457~459p

### 6.3.4 파티션을 활용한 대량 DELETE 튜닝
DELETE는 logging작업을 수반하므로 느리다. 테이블이 삭제 조건절 컬럼 기준으로 파티셔닝 되어 있고 인덱스도 로컬 파티션이라면 'alter table 테이블명 drop partition 파티션값' 를 사용하여 대량 데이터를 순시간에 삭제할 수 있다.

삭제조건이 여러개 있는 경우에는 1)임시 테이블 생성하고 남길 데이터만 복제 2)삭제 대상 테이블 파티션을 Truncate 3)임시 테이블에 복제해 둔 데이터를 원본 테이블에 입력 4)임시 테이블 drop 의 순서로 처리한다.

또 서비스 중단없이 파티션을 drop 또는 Truncate 하려면 아래 조건을 모두 만족해야한다.

* 파티션 키와 커팅 기준 컬럼이 일치해야 함
* 파티션 단위와 커팅 주기가 일치해야 함
* 모든 인덱스가 로컬 파티션 인덱스이어야 함

### 6.3.5 파티션을 활용한 대량 INSERT 튜닝
비파티션 테이블일때 대량 데이터를 Insert 하려면, 인덱스를 Unusable 시켰다가 재생성하는 방식이 더 빠를 수 있다. 파티션 테이블일 때 실무에서는 웬만하면 인덱스를 그대로 둔 상태로 Insert한다.